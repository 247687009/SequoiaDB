
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-us" xml:lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="copyright" content="(C) Copyright 2005"/>
<meta name="DC.rights.owner" content="(C) Copyright 2005"/>
<meta name="DC.Type" content="topic"/>
<meta name="DC.Title" content="与 MapReduce 集成"/>
<meta name="description" content="搭建 Hadoop 环境 我们支持 hadoop 1.x 和 hadoop 2.x。先安装配置好 Hadoop 配置连接环境 与 MapReduce 对接，需要准备 hadoop-connector.jar 和 sequoiadb.jar，这两个 jar 可以在 SequoiaDB 安装目录下面的 hadoop 目录中找到。 因为不同版本的 Hadoop 的 classpath 不一样，所以先查看 ..."/>
<meta name="DC.Relation" scheme="URI" content="../../hadoop_integration/hadooproot.html"/>
<meta name="DC.Format" content="XHTML"/>
<meta name="DC.Identifier" content="topic_1vk_h5v_xl"/>
<link rel="stylesheet" type="text/css" href="../../commonltr.css"/>
<link rel="stylesheet" type="text/css" href="../../assets/webhelp_topic.css"/>
<title>与 MapReduce 集成</title>
<script type="text/javascript" src="../../assets/jquery-1.3.2.js"> </script><script type="text/javascript" src="../../assets/jquery-ui-1.8.2.custom.min.js"> </script><script type="text/javascript" src="../../assets/frames_redirect.js"> </script><script type="text/javascript"><!--
    var prefix = "../../../index.html";
    var ratingFile = "";
    redirectToToc(window.location.search);
    function highlightSearchTerm(){
        if(parent.termsToHighlight != null){
        // highlight each term in the content view  
          for(i = 0 ; i < parent.termsToHighlight.length ; i++){        
              $('*', window.parent.frames[1].document).highlight(parent.termsToHighlight[i]);
          }
        }
    }
//--></script></head>
<body onload="highlightSearchTerm()" id="topic_1vk_h5v_xl"><a name="topic_1vk_h5v_xl"><!-- --></a>
<table class="nav"><tbody><tr><td><div class="navheader"><span class="frames" onclick="redirectFrames(location.pathname)"><script type="text/javascript"><!--
  if (parent.window.location.pathname == window.location.pathname ) document.write('With Frames');                    
                    --></script></span><a class="link" href="../../hadoop_integration/hadooproot.html" title="Hadoop 集成"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Hadoop 集成</span></a>  </div></td><td width="50%"><a class="navheader_parent_path" href="../../hadoop_integration/hadooproot.html" title="Hadoop 集成">Hadoop 集成</a></td></tr></tbody></table>

  <h1 class="title topictitle1">与 MapReduce 集成</h1>

  <div class="body">
    <div class="section"><h2 class="title sectiontitle">搭建 Hadoop 环境</h2>
      
      <p class="p">我们支持 hadoop 1.x 和 hadoop 2.x。先安装配置好 Hadoop</p>

    </div>

    <div class="section"><h2 class="title sectiontitle">配置连接环境</h2>
      
      <p class="p">与 MapReduce 对接，需要准备 hadoop-connector.jar 和 sequoiadb.jar，这两个 jar 可以在 SequoiaDB 安装目录下面的 hadoop 目录中找到。</p>

      <p class="p">因为不同版本的 Hadoop 的 classpath 不一样，所以先查看 hadoop 的 classpath，输入 hadoop classpath，在classpath 中选择一个目录，把 hadoop-connector.jar 和 sequoiadb.jar 放在目录里面，重启 hadoop 集群。</p>

    </div>

    <div class="section"><h2 class="title sectiontitle">编写 MapReduce</h2>
      
      <p class="p"><strong class="ph b">hadoop-connector.jar 中一些重要的类：</strong></p>

      <p class="p">    SequoiadbInputFormat：读取SequoiaDB的数据</p>

      <p class="p">    SequoiadbOutputFormat：向SequoiaDB中写入数据</p>

      <p class="p">    BSONWritable：BSONObject 的包装类，实现了 WritableComparable 接口。用于序列化 BSONObject 对象。</p>

      <p class="p"><strong class="ph b">SequoiaDB 和 MapReduce 的配置：</strong></p>

      <p class="p">    sequoiadb-hadoop.xml 是配置文件，放在你编写的 MapReduce 工程的源码根目录下面。</p>

      <p class="p">    sequoiadb.input.url：指定作为输入的 SequoiaDB 的 URL 路径，格式为：hostname1:port1,hostname2:port2,</p>

      <p class="p">    sequoiadb.in.collectionspace：指定作为输入的集合空间。</p>

      <p class="p">    sequoiadb.in.collection：指定作为输入的集合。</p>

      <p class="p">    sequoiadb.output.url：指定作为输出的 SequoiaDB 的 URL 路径。</p>

      <p class="p">    sequoiadb.out.collectionspace：指定作为输出的集合空间。</p>

      <p class="p">    sequoiadb.out.collection：指定作为输出的集合。</p>

      <p class="p">    sequoiadb.out.bulknum：指定每次向 SequoiaDB 写入的记录条数，对写入性能进行优化。</p>

      <p class="p"><strong class="ph b">示例</strong></p>

      <ul class="ul">
        <li class="li">      
      <p class="p">1. 下面是读取 HDFS 文件，处理后写入到 SequoiaDB 中去：</p>

      <pre class="pre codeblock">public class HdfsSequoiadbMR {
    static class MobileMapper extends  Mapper&lt;LongWritable,Text,Text,IntWritable&gt;{
        private static final IntWritable ONE=new IntWritable(1);
        @Override
        protected void map(LongWritable key, Text value, Context context)
                throws IOException, InterruptedException {
            String valueStr=value.toString();
            
            String mobile_prefix=valueStr.split(",")[3].substring(0,3);
            context.write(new Text(mobile_prefix), ONE);
        }
        
    }
    
    static class MobileReducer extends Reducer&lt;Text, IntWritable, NullWritable, BSONWritable&gt;{

        @Override
        protected void reduce(Text key, Iterable&lt;IntWritable&gt; values,Context context)
                throws IOException, InterruptedException {
                Iterator&lt;IntWritable&gt; iterator=values.iterator();
                long sum=0;
                while(iterator.hasNext()){
                    sum+=iterator.next().get();
                }
                BSONObject bson=new BasicBSONObject();
                bson.put("prefix", key.toString());
                bson.put("count", sum);
                context.write(null,new BSONWritable(bson));
        }
        
    }
    
    
    
    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
        if(args.length&lt;1){
            System.out.print("please set input path ");
            System.exit(1);
        }
        Configuration conf=new Configuration();
        conf.addResource("sequoiadb-hadoop.xml"); //加载配置文件
        Job job=Job.getInstance(conf);
        job.setJarByClass(HdfsSequoiadbMR.class);
        job.setJobName("HdfsSequoiadbMR");
        job.setInputFormatClass(TextInputFormat.class);
        job.setOutputFormatClass(SequoiadbOutputFormat.class); //reduce 输出写入到 SequoiaDB 中
        TextInputFormat.setInputPaths(job, new Path(args[0]));

        job.setMapperClass(MobileMapper.class);    
        job.setReducerClass(MobileReducer.class);
        
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);
        
        job.setOutputKeyClass(NullWritable.class);        
        job.setOutputValueClass(BSONWritable.class);
        
        job.waitForCompletion(true);
    }
}</pre>
</li>

      <li class="li"><p class="p">2. 读取 SequoiaDB 中数据处理后写入到 HDFS 中。</p>

      <pre class="pre codeblock">public class SequoiadbHdfsMR {
    /**
     * 
     * @author gaoshengjie
     *  read the data, count penple in a province
     */
    static class ProvinceMapper extends Mapper&lt;Object, BSONObject,IntWritable,IntWritable&gt;{
        private static final IntWritable ONE=new IntWritable(1);
        @Override
        protected void map(Object key, BSONObject value, Context context)
                throws IOException, InterruptedException {
            int province=(Integer) value.get("province_code");
            context.write(new IntWritable(province), ONE);
        }
            
    }
    
    static class ProvinceReducer extends Reducer&lt;IntWritable,IntWritable,IntWritable,LongWritable&gt;{

        @Override
        protected void reduce(IntWritable key, Iterable&lt;IntWritable&gt; values,
                Context context)
                throws IOException, InterruptedException {
            Iterator&lt;IntWritable&gt; iterator=values.iterator();
            long sum=0;
            while(iterator.hasNext()){
                sum+=iterator.next().get();
            }
            context.write(key,new LongWritable(sum));
        }

    }
    
    
    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
        if(args.length&lt;1){
            System.out.print("please set  output path ");
            System.exit(1);
        }
        Configuration conf=new Configuration();
        conf.addResource("sequoiadb-hadoop.xml");
        Job job=Job.getInstance(conf);
        job.setJarByClass(SequoiadbHdfsMR.class);
        job.setJobName("SequoiadbHdfsMR");
        job.setInputFormatClass(SequoiadbInputFormat.class);
        job.setOutputFormatClass(TextOutputFormat.class);

        
        FileOutputFormat.setOutputPath(job, new Path(args[0]+"/result"));
        
        job.setMapperClass(ProvinceMapper.class);    
        job.setReducerClass(ProvinceReducer.class);
        
        job.setMapOutputKeyClass(IntWritable.class);
        job.setMapOutputValueClass(IntWritable.class);
        
        job.setOutputKeyClass(IntWritable.class);        
        job.setOutputValueClass(LongWritable.class);
        
        job.waitForCompletion(true);
    }
}</pre>
</li>

      </ul>

      <p class="p">配置信息：</p>

      <pre class="pre codeblock">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;configuration&gt;
  &lt;property&gt;
     &lt;name&gt;sequoiadb.input.url&lt;/name&gt;
     &lt;value&gt;localhost:11810&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
     &lt;name&gt;sequoiadb.output.url&lt;/name&gt;
     &lt;value&gt;localhost:11810&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
     &lt;name&gt;sequoiadb.in.collectionspace&lt;/name&gt;
     &lt;value&gt;default&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
     &lt;name&gt;sequoiadb.in.collect&lt;/name&gt;
     &lt;value&gt;student&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
     &lt;name&gt;sequoiadb.out.collectionspace&lt;/name&gt;
     &lt;value&gt;default&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
     &lt;name&gt;sequoiadb.out.collect&lt;/name&gt;
     &lt;value&gt;result&lt;/value&gt;
  &lt;/property&gt;
    &lt;property&gt;
     &lt;name&gt;sequoiadb.out.bulknum&lt;/name&gt;
     &lt;value&gt;10&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;</pre>

    </div>

  </div>

<div class="related-links"/>
<div class="navfooter"><a class="link" href="../../hadoop_integration/hadooproot.html" title="Hadoop 集成"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Hadoop 集成</span></a>  <script type="text/javascript"><!--         
    function expand(){
        parent.tocwin.expandToTopic(window.location.href, this.getAttribute('href'));
    }
    var aArray = document.getElementsByTagName('a');
    var i;
    for (i = 0; i< aArray.length; i++){
      aArray[i].onclick = expand;
    }
//--></script></div><div class="footer"><a href="http://www.sequoiadb.com" target="_blank"><img src="../../assets/images/sequoiadb_logo.png" alt="SequoiaDB"/></a>SequoiaDB Version 1.11
          
    </div>
</body>
</html>